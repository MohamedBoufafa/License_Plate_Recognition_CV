{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 CRNN OCR - Algerian License Plates\n\n**Setup:** Enable GPU (T4) + Add your datasets + Update paths in Cell 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q albumentations"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, random, numpy as np\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport cv2, albumentations as A\n\nrandom.seed(42); np.random.seed(42); torch.manual_seed(42)\n\n# \u26a0\ufe0f UPDATE THESE PATHS!\nSYNTHETIC_DIR = '/kaggle/input/YOUR-SYNTHETIC-DATASET'\nREAL_DIR = '/kaggle/input/YOUR-REAL-DATASET'\nOUTPUT_DIR = '/kaggle/working/checkpoints'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nIMG_HEIGHT, IMG_WIDTH, NUM_CLASSES = 64, 200, 11\nBATCH_SIZE, NUM_EPOCHS, LR = 64, 100, 0.001\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f\"Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data loading\ndef scan_plates(directory):\n    images, labels = [], []\n    for p in Path(directory).rglob('*.jpg'):\n        label = p.stem.split('_')[0].zfill(11)\n        if 10 <= len(label) <= 11 and label.isdigit():\n            images.append(str(p)); labels.append(label)\n    return images, labels\n\ndef load_data():\n    synth_i, synth_l = scan_plates(SYNTHETIC_DIR)\n    real_i, real_l = scan_plates(REAL_DIR)\n    print(f\"Synthetic: {len(synth_i):,}, Real: {len(real_i):,}\")\n    \n    needed = min(int(len(real_i) * 0.8 / 0.2), len(synth_i))\n    if needed < len(synth_i):\n        idx = random.sample(range(len(synth_i)), needed)\n        synth_i = [synth_i[i] for i in idx]\n        synth_l = [synth_l[i] for i in idx]\n    \n    all_i = synth_i + real_i\n    all_l = synth_l + real_l\n    all_s = ['synthetic']*len(synth_i) + ['real']*len(real_i)\n    \n    combined = list(zip(all_i, all_l, all_s))\n    random.shuffle(combined)\n    all_i, all_l, all_s = zip(*combined)\n    \n    t_end = int(len(all_i) * 0.7)\n    v_end = t_end + int(len(all_i) * 0.15)\n    \n    return {\n        'train': (list(all_i[:t_end]), list(all_l[:t_end]), list(all_s[:t_end])),\n        'val': (list(all_i[t_end:v_end]), list(all_l[t_end:v_end]), list(all_s[t_end:v_end]))\n    }\n\n# Augmentation\nheavy_aug = A.Compose([\n    A.Rotate(limit=15, p=0.7), A.Perspective(scale=(0.02, 0.05), p=0.5),\n    A.RandomBrightnessContrast(0.3, 0.3, p=0.8),\n    A.OneOf([A.GaussianBlur((3,7), p=1), A.MotionBlur(5, p=1)], p=0.6),\n    A.GaussNoise(p=0.5), A.Resize(IMG_HEIGHT, IMG_WIDTH)\n])\n\nmedium_aug = A.Compose([\n    A.Rotate(limit=10, p=0.5), A.RandomBrightnessContrast(0.2, 0.2, p=0.6),\n    A.Resize(IMG_HEIGHT, IMG_WIDTH)\n])\n\nno_aug = A.Compose([A.Resize(IMG_HEIGHT, IMG_WIDTH)])\n\nprint(\"\u2705 Data functions ready\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset\nclass LPDataset(Dataset):\n    def __init__(self, paths, labels, sources, train=True):\n        self.paths, self.labels, self.sources, self.train = paths, labels, sources, train\n        self.c2i = {str(i): i for i in range(10)}\n    \n    def __len__(self): return len(self.paths)\n    \n    def __getitem__(self, i):\n        img = cv2.imread(self.paths[i])\n        if img is None: img = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)\n        else: img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.train:\n            img = (heavy_aug if self.sources[i]=='real' else medium_aug)(image=img)['image']\n        else:\n            img = no_aug(image=img)['image']\n        \n        img = torch.from_numpy(img.astype(np.float32)/255.0).permute(2,0,1)\n        label = [self.c2i[c] for c in self.labels[i]]\n        return img, torch.LongTensor(label), len(label)\n\ndef collate_fn(batch):\n    imgs, labs, lens = zip(*batch)\n    return torch.stack(imgs), torch.cat(labs), torch.LongTensor(lens)\n\nprint(\"\u2705 Dataset ready\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CRNN Model\nclass CRNN(nn.Module):\n    def __init__(self, h=64, w=200, nc=11, hs=256):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3,64,3,1,1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2,2),\n            nn.Conv2d(64,128,3,1,1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2,2),\n            nn.Conv2d(128,256,3,1,1), nn.BatchNorm2d(256), nn.ReLU(True),\n            nn.Conv2d(256,256,3,1,1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d((2,1),(2,1)),\n            nn.Conv2d(256,512,3,1,1), nn.BatchNorm2d(512), nn.ReLU(True),\n            nn.Conv2d(512,512,3,1,1), nn.BatchNorm2d(512), nn.ReLU(True), nn.MaxPool2d((2,1),(2,1))\n        )\n        self.rnn = nn.LSTM(512*(h//16), hs, 2, True, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hs*2, nc)\n    \n    def forward(self, x):\n        x = self.cnn(x)\n        b,c,h,w = x.size()\n        x = x.permute(0,3,1,2).reshape(b,w,c*h)\n        x, _ = self.rnn(x)\n        x = self.fc(x).permute(1,0,2)\n        return F.log_softmax(x, 2)\n\nprint(\"\u2705 Model ready\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training functions\ndef train_epoch(model, loader, crit, opt, dev):\n    model.train()\n    total = 0\n    for imgs, labs, lens in tqdm(loader, desc='Train'):\n        imgs, labs = imgs.to(dev), labs.to(dev)\n        out = model(imgs)\n        T, B = out.size(0), out.size(1)\n        loss = crit(out, labs, torch.full((B,), T, dtype=torch.long), lens)\n        opt.zero_grad(); loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n        opt.step()\n        total += loss.item()\n    return total / len(loader)\n\ndef validate(model, loader, crit, dev):\n    model.eval()\n    total, correct, count = 0, 0, 0\n    with torch.no_grad():\n        for imgs, labs, lens in tqdm(loader, desc='Val'):\n            imgs, labs = imgs.to(dev), labs.to(dev)\n            out = model(imgs)\n            T, B = out.size(0), out.size(1)\n            loss = crit(out, labs, torch.full((B,), T, dtype=torch.long), lens)\n            total += loss.item()\n            \n            _, preds = out.max(2)\n            preds = preds.T\n            offset = 0\n            for i, l in enumerate(lens):\n                pred = preds[i].cpu().numpy()\n                tgt = labs[offset:offset+l].cpu().numpy()\n                offset += l\n                \n                dec = []\n                prev = -1\n                for p in pred:\n                    if p!=10 and p!=prev: dec.append(p)\n                    prev = p\n                dec = dec[:len(tgt)]\n                \n                if len(dec)==len(tgt) and all(p==t for p,t in zip(dec,tgt)):\n                    correct += 1\n                count += 1\n    \n    return total/len(loader), correct/count\n\nprint(\"\u2705 Training functions ready\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Main training\nprint(\"=\"*60)\nprint(\"\ud83d\ude80 TRAINING START\")\nprint(\"=\"*60)\n\nsplits = load_data()\ntrain_ds = LPDataset(*splits['train'], True)\nval_ds = LPDataset(*splits['val'], False)\n\ntrain_ld = DataLoader(train_ds, BATCH_SIZE, True, num_workers=2, collate_fn=collate_fn, pin_memory=True)\nval_ld = DataLoader(val_ds, BATCH_SIZE, False, num_workers=2, collate_fn=collate_fn, pin_memory=True)\n\nprint(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")\n\nmodel = CRNN().to(DEVICE)\nprint(f\"Params: {sum(p.numel() for p in model.parameters()):,}\")\n\ncrit = nn.CTCLoss(blank=10, zero_infinity=True)\nopt = optim.Adam(model.parameters(), lr=LR)\nsch = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', 0.5, 5, verbose=True)\n\nbest_acc = 0\nhistory = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n    \n    train_loss = train_epoch(model, train_ld, crit, opt, DEVICE)\n    val_loss, val_acc = validate(model, val_ld, crit, DEVICE)\n    sch.step(val_loss)\n    \n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    \n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n    \n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), f\"{OUTPUT_DIR}/best_model.pth\")\n        print(f\"\u2705 Best: {best_acc*100:.2f}%\")\n\nprint(f\"\\n\ud83c\udf89 Done! Best: {best_acc*100:.2f}%\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot results\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(history['train_loss'], label='Train')\nplt.plot(history['val_loss'], label='Val')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot([x*100 for x in history['val_acc']])\nplt.xlabel('Epoch'); plt.ylabel('Acc (%)'); plt.title('Validation Accuracy')\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/curves.png')\nplt.show()\n\nprint(f\"Best: {max(history['val_acc'])*100:.2f}%\")"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}